import os
from groq import Groq
from dotenv import load_dotenv , dotenv_values
import pandas as pd
from pandas import read_csv

load_dotenv()
api_key = os.getenv("GROQ_API_KEY")

client = Groq(api_key=api_key)
model ="openai/gpt-oss-120b"

def load_data():
    """Charge les fichiers CSV et texte avec int√©gration des summaries"""
    data = {}
    
    # Charger les CSV
    try:
        data['models_results'] = pd.read_csv('./data_export/deep_models_results.csv')
        data['granger_test'] = pd.read_csv('./data_export/granger_causality.csv')
        data['stationarity'] = pd.read_csv('./data_export/tests_stationnarite.csv')
        data['desc_tsla'] = pd.read_csv('./data_export/desc_tsla.csv')
    except Exception as e:
        print(f"Erreur chargement CSV: {e}")
    
    # Charger les r√©sum√©s texte et les mapper aux mod√®les
    model_summaries = {
        'arima': './data_export/summary_arima.txt',
        'arimax': './data_export/summary_arimax.txt',
        'sarima': './data_export/summary_sarima.txt',
        'ets': './data_export/summary_ets.txt',
        'garch': './data_export/summary_garch.txt',
        'garch_student': './data_export/summary_garch_student.txt',
        'var': './data_export/summary_var.txt',
        'prophet': './data_export/summary_prophet.txt'
    }
    
    # Charger chaque summary
    summaries = {}
    for model_key, filename in model_summaries.items():
        try:
            with open(filename, 'r', encoding='utf-8') as file:
                summaries[model_key] = file.read()
        except:
            summaries[model_key] = "Fichier non trouv√©"
    
    # Ajouter les summaries aux mod√®les dans le dataframe
    def get_summary(model_name):
        """Retourne le summary correspondant au mod√®le"""
        model_lower = model_name.lower().replace('_', ' ').replace('-', ' ')
        for key, summary in summaries.items():
            if key in model_lower:
                return summary[:500]  # Aper√ßu de 500 caract√®res
        return "Pas de summary disponible"
    
    # Ajouter une colonne avec les summaries
    data['models_results']['Summary'] = data['models_results']['Modele'].apply(get_summary)
    data['full_summaries'] = summaries
    
    return data
data = load_data()

def generate_hypotheses(data):
    """Point 1: G√©n√©rer automatiquement des hypoth√®ses √† partir des stats descriptives"""
    
    models_df = data['models_results']
    desc_stats_df = data['desc_tsla']
    stationarity_df = data['stationarity']
    granger_df = data['granger_test']
    
    best_returns = models_df[models_df['Type'] == 'Returns'].nsmallest(1, 'RMSE_Test')
    best_model = best_returns['Modele'].values[0]
    best_rmse = best_returns['RMSE_Test'].values[0]
    
    # Extraire les stats descriptives
    desc_stats_text = desc_stats_df.to_string()
    stationarity_text = stationarity_df.to_string()
    granger_text = granger_df.to_string()
    
    # Calculer des statistiques suppl√©mentaires
    skewness_info = desc_stats_df.to_dict() if 'Skewness' in desc_stats_df.columns else {}
    kurtosis_info = desc_stats_df.to_dict() if 'Kurtosis' in desc_stats_df.columns else {}
    
    prompt = f"""
Tu es expert en machine learning et analyse statistique de s√©ries temporelles financi√®res.

 STATISTIQUES DESCRIPTIVES - TESLA (TSLA):
{desc_stats_text}

 TESTS DE STATIONNARIT√â:
{stationarity_text}

üîó CAUSALIT√â GRANGER:
{granger_text}

MEILLEUR MOD√àLE ACTUEL: {best_model} (RMSE Test: {best_rmse:.4f})

T√ÇCHE - G√âN√âRER HYPOTH√àSES √Ä PARTIR DES STATS DESCRIPTIVES:

En analysant les statistiques ci-dessus, identifie les CARACT√âRISTIQUES de la s√©rie:
- Asym√©trie (Skewness)? Queues √©paisses (Kurtosis)?
- Stationnarit√© diff√©rente pour Returns vs Close?
- Absence de causalit√© entre variables?
- Volatilit√©? Tendance? Saisonnalit√©?

PUIS propose 5 HYPOTH√àSES DE MOD√àLES adapt√©es √† ces caract√©ristiques.

Pour CHAQUE hypoth√®se:
1. NOM DU MOD√àLE
2. CARACT√âRISTIQUE STATISTIQUE D√âTECT√âE (d'apr√®s les stats descriptives)
3. POURQUOI CE MOD√àLE S'ADAPTE √Ä CES CARACT√âRISTIQUES
4. AM√âLIORATION ATTENDUE vs {best_model}
5. DONN√âES/FEATURES N√âCESSAIRES
6. COMPLEXIT√â (Faible/Moyen/√âlev√©)



Exemple format:
Hypoth√®se 1:
Nom: [mod√®le]
Caract√©ristique d√©tect√©e: [asym√©trie, kurtosis √©lev√©, non-stationnarit√©, etc.]
Justification: [Parce que les stats montrent...]
Am√©lioration attendue: [X% de r√©duction RMSE]
Donn√©es: [RSI, Volume, etc.]
Complexit√©: [Moyen]


IMPORTANT:
- Chaque hypoth√®se DOIT √™tre ancr√©e dans les stats observ√©es
- Pas de suggestions g√©n√©riques, du concret bas√© sur les donn√©es
- Mentionne les valeurs num√©riques des stats pour justifier
-Donner des paragraphes bien d√©lopp√© pour chaque point
"""
    
    
    response = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
        
    )
    
    return response.choices[0].message.content


def explain_results(data):
    """Point 2: Expliquer les r√©sultats de mani√®re vulgaris√©e"""
    print("   G√©n√©ration du rapport vulgaris√©...")

    models_df = data['models_results']
    # S√©lectionner les top 3 mod√®les selon RMSE_Test
    top_models = models_df[models_df['Type'] == 'Returns'].nsmallest(3, 'RMSE_Test')
    summaries = data['full_summaries']

    # Construire un tableau r√©capitulatif
    recap = ""
    for idx, row in top_models.iterrows():
         recap += (
            f"\nMod√®le : {row['Modele']}\n"
            f"- RMSE Test : {row['RMSE_Test']:.6f}\n"
            f"- MAE Test : {row['MAE_Test']:.6f}\n"
            f"- MAPE Test : {row['MAPE_Test']:.2f}%\n"
            f"- AIC : {row.get('AIC', 'N/A')}\n"
            f"- BIC : {row.get('BIC', 'N/A')}\n")


    prompt = f"""Tu es un vulgarisateur scientifique pour investisseurs non-techniques.

R√âSULTATS DES 3 MEILLEURS MOD√àLES :
{recap}

T√ÇCHE: √âcris un RAPPORT qui explique:

1Ô∏è M√âTRIQUES EXPLIQU√âES SIMPLEMENT
   - Qu'est-ce que RMSE, MAE, MAPE , AIC , BIC? (analogies simples, pas de formules)
   - "L'erreur moyenne est de..."
   - Qu'est-ce que √ßa signifie pour pr√©dire le prix?

2  Les points FORTS ET FAIBLES DE CHAQUE MOD√àLE
   - Pourquoi ces mod√®les gagnent?
   - Ses 3 forces principales
   - Ses 2-3 limitations r√©elles

3Ô∏è IMPLICATIONS PRATIQUES POUR UN INVESTISSEUR
   - Comment √ßa aide pour investir?
   - Quel est le risque r√©el?
   - Comment l'utiliser correctement?

4Ô∏è COMPARAISON 
   - Pourquoi les classement est ainsi ?
   - Qu'est-ce qui diff√©rencie le 1er du 2e et 3e?

STYLE:
- Langage tr√®s simple (niveau lyc√©e)
- Honn√™te sur les limites
- Pas de promesses exag√©r√©es
- Assume que le lecteur ne sait rien en ML
-Donner des paragraphes bien d√©lopp√© pour chaque point

"""

    response = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
        
    )
    
    return response.choices[0].message.content


def generate_recommendation(data):
    """Point 3: G√©n√©rer des recommandations d‚Äôinvestissement simul√©es (expliciter les limites et risques)"""
    models_df = data['models_results']
   
    top_models = models_df[models_df['Type'] == 'Returns'].nsmallest(3, 'RMSE_Test')
    recap = ""
    for idx, row in top_models.iterrows():
        recap += (
            f"\nMod√®le : {row['Modele']}\n"
            f"- RMSE Test : {row['RMSE_Test']:.6f}\n"
            f"- MAE Test : {row['MAE_Test']:.6f}\n"
            f"- MAPE Test : {row['MAPE_Test']:.2f}%\n"
        )

    prompt = f"""Tu es un conseiller financier prudent et objectif.

R√âSULTATS DES 3 MEILLEURS MOD√àLES :
{recap}

T√ÇCHE : G√©n√®re une recommandation d'investissement simul√©e bas√©e sur ces r√©sultats.

Pour chaque recommandation:
- Action 
- Horizon (court/moyen/long terme)
- Mentionne les incertitudes, la volatilit√©, et les risques de perte.
- Des conseils pratiques pour utiliser ces pr√©visions de fa√ßon responsable.
- 1-2 risques majeurs
- AVERTISSEMENT clair sur les limites

IMPORTANT: 
- C'est une SIMULATION √©ducative, PAS un conseil professionnel
- Rappelle que les march√©s sont impr√©visibles
- Les mod√®les pr√©dictifs comportent des erreurs
- Ne pas investir r√©ellement sur la base de cet exercice
"""

    response = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
    )
    return response.choices[0].message.content

def compare_human_vs_ai(data, human_analysis=None):
    """Compare les analyses humaine et IA"""
    
    # Analyse IA
    ai_analysis = explain_results(data)
    
    # Analyse humaine (exemple si non fournie)
    if not human_analysis:
        human_analysis = """
        ANALYSE HUMAINE:
       - Les rendements sont stationnaires (test ADF p < 0.05).
- Pas d'autocorr√©lation significative dans les r√©sidus des mod√®les ARIMA/SARIMA (test Ljung-Box p > 0.05).
- L'asym√©trie et les queues √©paisses ne sont pas bien captur√©es par les mod√®les lin√©aires.
- Aucune causalit√© de Granger d√©tect√©e entre les variables (p > 0.05).
- Le mod√®le ARIMA capture correctement la dynamique des rendements, mais reste limit√© sur les extr√™mes.
- ARIMAX offre les meilleures performances sur les rendements (RMSE Test = 0.0324), gr√¢ce √† l'int√©gration des variables exog√®nes (RSI, Price_Range).
- LSTM obtient un RMSE proche (0.0348), mais sa complexit√© rend l'interpr√©tation plus difficile pour un investisseur.
- Le mod√®le GARCH Student-t capture mieux la volatilit√© et les extr√™mes, ce qui est important pour la gestion du risque.
- Le mod√®le ETS ne parvient pas √† bien pr√©dire les prix de cl√¥ture (erreur √©lev√©e).
- Prophet-RNN et ARIMA-LSTM (mod√®les hybrides) montrent de bonnes performances, en particulier lors de changements de tendance ou de volatilit√©.
- Au global, ARIMAX reste le meilleur pour la pr√©vision des rendements parmi les mod√®les classiques, mais les mod√®les deep/hybrides sont prometteurs pour des dynamiques plus complexes.

        """
    
    prompt = f"""
Compare ces deux analyses:

ANALYSE HUMAINE:
{human_analysis}

ANALYSE IA:
{ai_analysis}

√âvalue:
1. Points d'ACCORD (quoi de similaire?)
2. Points de DIVERGENCE (diff√©rences principales)
3. Laquelle est plus fiable et pourquoi?
4. Combin√© ensemble, qu'en conclure?
5-Donner des paragraphes bien d√©velopp√©s pour chaque point

Sois honn√™te et √©quilibr√© .
"""
    
    response = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.6,
       
    )
    
    comparison_result = response.choices[0].message.content
    
    return {
        "human_analysis": human_analysis,
        "ai_analysis": ai_analysis,
        "comparison": comparison_result
    }

def generate_report(data, human_analysis=None):
    """G√©n√®re le rapport complet"""
    hypotheses = generate_hypotheses(data)
    explanation = explain_results(data)
    recommendation = generate_recommendation(data)
    comparison = compare_human_vs_ai(data, human_analysis)
    
    report = f"""
RAPPORT D'ANALYSE DES S√âRIES TEMPORELLES DE TESLA (TSLA)
1Ô∏è HYPOTH√àSES DE MOD√àLES PROPOS√âES:
{hypotheses}
2Ô∏è EXPLICATION DES R√âSULTATS:
{explanation}
3Ô∏è RECOMMANDATION D'INVESTISSEMENT SIMUL√âE:
{recommendation}
4Ô∏è COMPARAISON ANALYSE HUMAINE VS IA:
- Analyse Humaine:
{comparison['human_analysis']}
- Comparaison:
{comparison['comparison']}
*Ce rapport a √©t√© g√©n√©r√© automatiquement √† l‚Äôaide d‚Äôun LLM. Les r√©sultats sont √† vis√©e p√©dagogique et ne constituent pas un conseil d‚Äôinvestissement.*
"""
    return report

def main():
    
    data = load_data()

    
    report = generate_report(data)

    report_dir = os.path.join(os.getcwd(), "report")
    os.makedirs(report_dir, exist_ok=True)

    report_path = os.path.join(report_dir, "rapport_tesla_llm.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\n Rapport g√©n√©r√© et export√© ici : {report_path}\n")

if __name__ == "__main__":
    main()